{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZWrvHYSWs3g"
      },
      "source": [
        "# Part 1: Downloading Dataset\n",
        "Download the `ocr-data.zip` file from either kaggle or google drive, currently this notebook using kaggle API. Before running the cells below, please drop the `kaggle.json` credentials file to you colab directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsEcdJEKXEA0"
      },
      "source": [
        "## Method 1: Using Kaggle API\n",
        "For some reason, downloading the dataset using Kaggle API is much faster than using google drive API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxZEhEw5u4Gs",
        "outputId": "8e465ca1-3777-49f7-b2f2-049edeb8e39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jkBwPYdnLeKB"
      },
      "outputs": [],
      "source": [
        "# create .kaggle directory in root direcory\n",
        "!mkdir -p ~/.kaggle\n",
        "# copy kaggle.json to ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "# change file permission for kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9MDCMauxDxC",
        "outputId": "38e3d291-df2d-4e8e-f6fe-49129eed7f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ocr-data.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "# download ocr dataset\n",
        "!kaggle datasets download -d aidapearson/ocr-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuN31eldGJWa",
        "outputId": "87e5e410-aee6-49a6-ec93-2133c7474aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ocr-data.zip\n",
            "replace raw_train_data/batch_1/JSON/kaggle_data_1.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# unzip the retrieved dataset into `raw_train_data`\n",
        "!unzip ocr-data.zip -d raw_train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeQyG6OIYDTN"
      },
      "source": [
        "## Method 2: Using Google Drive API\n",
        "Slower download speed than Kaggle API so currently not used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "x7NUhnU9W2w1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install google-auth google-auth-oauthlib google-auth-httplib2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wDWpgFrXSBmp"
      },
      "outputs": [],
      "source": [
        "# # Authenticate with service account credentials\n",
        "# from google.oauth2 import service_account\n",
        "# from google.auth.transport.requests import Request\n",
        "# # Access Google Drive using the authenticated credentials\n",
        "# from googleapiclient.discovery import build\n",
        "# from googleapiclient.http import MediaFileUpload,MediaIoBaseDownload\n",
        "# import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hHjRpOUWSTuD"
      },
      "outputs": [],
      "source": [
        "# credentials = service_account.Credentials.from_service_account_file(\n",
        "#     '/content/project-50021-415714-5d993bed20f3.json',\n",
        "#     scopes=['https://www.googleapis.com/auth/drive']\n",
        "# )\n",
        "# # Authenticate the credentials\n",
        "# credentials.refresh(Request())\n",
        "# # Build a Drive service object\n",
        "# drive_service = build('drive', 'v3', credentials=credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BGFFQxOFs5-5"
      },
      "outputs": [],
      "source": [
        "# Example: List files in Drive\n",
        "# results = drive_service.files().list(pageSize=10).execute()\n",
        "# items = results.get('files', [])\n",
        "\n",
        "# if not items:\n",
        "#     print('No files found.')\n",
        "# else:\n",
        "#     print('Files:')\n",
        "#     for item in items:\n",
        "#         print(f\"{item['name']} ({item['id']})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "npVf9Sp3vSAo"
      },
      "outputs": [],
      "source": [
        "# file_name = \"ocr-data.zip\"\n",
        "\n",
        "# file_metadata = {\"name\": \"ocr-data.zip\"}\n",
        "# media = MediaFileUpload(\"/content/ocr-data.zip\", mimetype=\"application/zip\")\n",
        "# uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "72KR37IrAXox"
      },
      "outputs": [],
      "source": [
        "\n",
        "# file_id = \"1uiNTe5CL3USzw2N-ShVWyD9IxdUlicYe\"\n",
        "# # pylint: disable=maybe-no-member\n",
        "# request = drive_service.files().get_media(fileId=file_id)\n",
        "# fh = io.FileIO('ocr-data.zip', mode='wb')\n",
        "# downloader = MediaIoBaseDownload(fh, request)\n",
        "# done = False\n",
        "# while done is False:\n",
        "#   status, done = downloader.next_chunk()\n",
        "#   print(f\"Download {int(status.progress() * 100)}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4eURvbtZ00O"
      },
      "source": [
        "## Part 2: A custom Dataset object\n",
        "A dataset object that should be modified according to the model being trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clVU1p2OavXJ"
      },
      "source": [
        "### Helper function to return a list of bounding box coordinates and the corresponding label for the object in each bounding box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "A0qCDGzKf0Y1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def create_bounding_box_labels(input_json_file,box_labels_dir):\n",
        "    \"\"\"\n",
        "    for each image, create a file listing the coordinates of bounding boxes of latex chars of the image\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(f\"{input_json_file}\", 'r') as f:\n",
        "        data = json.load(f)\n",
        "    data = list(data)\n",
        "    data.sort(key = lambda x: x[\"uuid\"])\n",
        "    bounding_box_dict = {}\n",
        "    for d in data:\n",
        "        # get output file name\n",
        "        file_name = f\"{d['uuid']}.jpg\"\n",
        "        # extract coordinates from each item in json array\n",
        "        xmins = d[\"image_data\"][\"xmins\"]\n",
        "        ymins = d[\"image_data\"][\"ymins\"]\n",
        "        xmaxs = d[\"image_data\"][\"xmaxs\"]\n",
        "        ymaxs = d[\"image_data\"][\"ymaxs\"]\n",
        "        # make list of bounding box coordinates for each LaTeX character\n",
        "        bounding_box_dict[file_name] = [[xmin,ymin,xmax,ymax]\n",
        "                             for xmin,ymin,xmax,ymax in zip(xmins, ymins, xmaxs, ymaxs)]\n",
        "    return bounding_box_dict\n",
        "\n",
        "def set_default(obj):\n",
        "    if isinstance(obj, set):\n",
        "        return list(obj)\n",
        "    raise TypeError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p7SmypAbfsv"
      },
      "source": [
        "### Dataset object for the model to be trained with.\n",
        "\n",
        "Currently `MathDataset` only handles two class labels:\n",
        "- a latex object\n",
        "- not a latex object\n",
        "\n",
        "TODO\n",
        "\n",
        "Add more classes such as:\n",
        "- number\n",
        "- operator ($+$,$-$,$\\div$,$\\times$, etc.)\n",
        "- symbol (arrow, fraction, parenthesis)\n",
        "- functions ($lim$, $tan$, $sin$, $cos$, etc.)\n",
        "- mathematical variables ($x$, $y$, $z$, $\\alpha$, $\\beta$, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Zta2mbhXl_CS"
      },
      "outputs": [],
      "source": [
        "class MathDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset object for a single batch in the dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_number):\n",
        "        self.batch_dir = f\"raw_train_data/batch_{str(batch_number)}/background_images\"\n",
        "        self.file_names = sorted([filename\n",
        "                                  for dirname, _, filenames in os.walk(batch_dir)\n",
        "                                  for filename in filenames])\n",
        "        self.no_of_files = len(self.file_names)\n",
        "\n",
        "        training_label_file_name = f\"raw_train_data/batch_{str(batch_number)}/JSON/kaggle_data_{str(batch_number)}.json\"\n",
        "        bounding_box_labels_dir = f\"content/output/bounding_box_labels/batch_{str(batch_number)}\"\n",
        "        self.bounding_box_dict = create_bounding_box_labels(training_label_file_name,bounding_box_labels_dir)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        each item is a tuple of (image: Tensor, target:dict:{boxes:list[list[int]],labels:list[int]} )\n",
        "        \"\"\"\n",
        "        file_name = self.file_names[idx]\n",
        "        image = Image.open(f\"{self.batch_dir}/{file_name}\") # open colour image\n",
        "        binary_image = convert_image_to_binary(image, thresh = 127) # convert colour image to black and white image\n",
        "        # preprocessing for the binary_image object\n",
        "        process = transforms.Compose([\n",
        "                                transforms.PILToTensor(), # convert it to a tensor\n",
        "                                transforms.Resize((600,600),antialias = True) # convert it to 600 x 600\n",
        "                                ])\n",
        "        # apply preprocessing to the binary_image\n",
        "        final_image = process(binary_image).float()\n",
        "        # create target object for training\n",
        "        target = {}\n",
        "        # \"boxes\" is a list of bounding boxes for each detected object. Each bounding box is just a l;ist of\n",
        "        # (xmin,ymin,xmax,ymax)\n",
        "        target[\"boxes\"] = torch.tensor(self.bounding_box_dict.get(file_name))\n",
        "        # \"labels\" is a list of class labels for each bounding box in \"boxes\".\n",
        "        # TODO: Currently every label is just 1, but once we have more classes, the \"labels\" entry of target will have a larger domain of possible values.\n",
        "        target[\"labels\"] = torch.ones(len(target.get(\"boxes\")), dtype=torch.int64)\n",
        "        return final_image, target\n",
        "    def __len__(self):\n",
        "        return self.no_of_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcn-4UWTZjcl"
      },
      "source": [
        "## Part 3: Object Detection Model\n",
        "TODO:\n",
        "Code for training an object detection model.\n",
        "We should probably try different object detection models\n",
        "\n",
        "some built in models in pytorch include:\n",
        "1. Faster R-CNN\n",
        "2. Mask R-CNN\n",
        "3. YOLO (You Only Look Once)\n",
        "4. RetinaNet\n",
        "and many more.\n",
        "\n",
        "Then evaluate their performance and choose the best one."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
